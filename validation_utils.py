import pandas as pd
import numpy as np
from telegram_utils import send_telegram_message, send_long_telegram_message  # í…”ë ˆê·¸ë¨ ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸
from tqdm import tqdm
from stock_utils import load_daily_craw_data  

def process_and_report_validation_results(validation_results, settings):
    """
    Processes validation results, calculates performance, saves data, and sends Telegram messages.

    Args:
        validation_results (pd.DataFrame): DataFrame containing validation results.
        settings (dict): Dictionary containing settings (e.g., database credentials).
    """
    if validation_results.empty:
        print("No validation results to process.")
        return

    # Convert column names to lowercase
    validation_results.columns = validation_results.columns.str.lower()

    # Create performance DataFrame
    performance_df = evaluate_performance(validation_results, settings['craw_db'])

    # Save performance_df to the deep_learning database
    save_performance_to_deeplearning(performance_df, settings)
    
    # Send validation summary
    send_validation_summary(validation_results, performance_df, settings)


def calculate_performance(df, start_date, end_date):
    try:
        print('Caluating performance')
        df['date'] = pd.to_datetime(df['date'])
        
        # ë‹¤ìŒë‚  ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°(ì˜¤ëŠ˜ì´ ë§ˆì§€ë§‰ ë‚ ì§œì¸ ê²½ìš°) ì²´í¬
        if df[df['date'] >= start_date].empty:
            print(f"No data available from {start_date} (next trading day). Returning 0.")
            return 0.0, 0.0, 0.0, 0.0  # ìµœëŒ€ ìˆ˜ìµë¥ , ìµœëŒ€ ì†ì‹¤ë¥ , ì˜ˆìƒ ìˆ˜ìµë¥ , ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥  ë°˜í™˜
        
        # ë§¤ìˆ˜ì¼(start_date)ì˜ ì¢…ê°€ ê°€ì ¸ì˜¤ê¸° - ë§¤ìˆ˜ê°€ê²© ì„¤ì •
        buy_data = df[df['date'] >= start_date].iloc[0]
        buy_price = buy_data['close']
        buy_date = buy_data['date']
        
        # ë§¤ìˆ˜ì¼ë¶€í„° 60ì¼ê°„ì˜ ë°ì´í„° ì„ íƒ
        period_df = df[(df['date'] >= buy_date) & (df['date'] <= end_date)]
        
        if period_df.empty or len(period_df) < 2:  # ìµœì†Œ 2ê°œ ì´ìƒì˜ ë°ì´í„°ê°€ í•„ìš”
            print(f"Insufficient data between {buy_date} and {end_date}")
            return 0.0, 0.0, 0.0, 0.0  # ìµœëŒ€ ìˆ˜ìµë¥ , ìµœëŒ€ ì†ì‹¤ë¥ , ì˜ˆìƒ ìˆ˜ìµë¥ , ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥  ë°˜í™˜
        
        # ìµœëŒ€ ìˆ˜ìµë¥  ê³„ì‚° (ìµœê³ ê°€ ê¸°ì¤€)
        max_price = period_df['high'].max()
        max_profit_rate = (max_price - buy_price) / buy_price * 100
        
        # ìµœëŒ€ ì†ì‹¤ë¥  ê³„ì‚° (ìµœì €ê°€ ê¸°ì¤€)
        min_price = period_df['low'].min()
        max_loss_rate = (min_price - buy_price) / buy_price * 100  # ì†ì‹¤ì€ ìŒìˆ˜ë¡œ í‘œí˜„ë¨
        
        # ì˜ˆìƒ ìˆ˜ìµë¥  = ìµœëŒ€ ìˆ˜ìµë¥  - |ìµœëŒ€ ì†ì‹¤ë¥ |
        estimated_profit_rate = max_profit_rate - abs(max_loss_rate)
        
        # ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥  ê³„ì‚° (ì˜ˆì‹œ)
        risk_adjusted_return = estimated_profit_rate / abs(max_loss_rate)
        
        print(f"Buy price: {buy_price}, Max price: {max_price}, Min price: {min_price}")
        print(f"Max profit: {max_profit_rate:.2f}%, Max loss: {max_loss_rate:.2f}%, Estimated profit: {estimated_profit_rate:.2f}%, Risk-adjusted return: {risk_adjusted_return:.2f}%")
        
        return max_profit_rate, max_loss_rate, estimated_profit_rate, risk_adjusted_return
        
    except Exception as e:
        print(f'Error evaluating performance: {e}')
        import traceback
        traceback.print_exc()
        return 0.0, 0.0, 0.0, 0.0  # ì˜¤ë¥˜ ë°œìƒ ì‹œ 0 ë°˜í™˜


def evaluate_performance(validation_results, craw_db):

    # í•„í„°ë§ëœ ë‚ ì§œ-ì¢…ëª© ì¡°í•©ì— ëŒ€í•´ ì„±ëŠ¥ í‰ê°€
    performance_results = []
    for index, row in tqdm(validation_results.iterrows(), total=len(validation_results), desc="Evaluating performance"):
        stock_name = row['stock_name']  # stock_name -> stock_name
        pattern_date = row['date']
        confidence = row.get('prediction', 0)  # prediction ê°’ìœ¼ë¡œ ëŒ€ì²´
        performance_start_date = pattern_date + pd.Timedelta(days=1)  # ë‹¤ìŒë‚  ë§¤ìˆ˜
        performance_end_date = performance_start_date + pd.Timedelta(days=60)
        
        df = load_daily_craw_data(craw_db, stock_name, performance_start_date, performance_end_date)
        print(f"Evaluating performance for {stock_name} from {performance_start_date} to {performance_end_date}: {len(df)} rows")
        
        # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ê²°ê³¼ì— í¬í•¨ (ë§ˆì§€ë§‰ ë‚ ì§œ ì²˜ë¦¬ë¥¼ ìœ„í•¨)
        if df.empty:
            print(f"No data available for {stock_name} after {pattern_date}. Including with 0 return.")
            performance_results.append({
                'stock_name': stock_name,  # stock_name -> stock_name
                'date': pattern_date,
                'start_date': performance_start_date,
                'end_date': performance_end_date,
                'max_return': 0.0,  # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0 ë°˜í™˜
                'max_loss': 0.0,  # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0 ë°˜í™˜
                'estimated_profit_rate': 0.0,  # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° 0 ë°˜í™˜
                'risk_adjusted_return': 0.0, # risk_adjusted_return ê°’ ì¶”ê°€
                'confidence': confidence,  # confidence ê°’ ì €ì¥
            })
        else:
            max_return, max_loss, estimated_profit_rate, risk_adjusted_return = calculate_performance(df, performance_start_date, performance_end_date)
            
            # Noneì´ ë°˜í™˜ë˜ëŠ” ê²½ìš°ì—ë„ 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ í¬í•¨
            if max_return is None:
                max_return = 0.0
            if max_loss is None:
                max_loss = 0.0
            if estimated_profit_rate is None:
                estimated_profit_rate = 0.0
            if risk_adjusted_return is None:
                risk_adjusted_return = 0.0
                
            performance_results.append({
                'stock_name': stock_name,  # stock_name -> stock_name
                'date': pattern_date,
                'start_date': performance_start_date,
                'end_date': performance_end_date,
                'max_return': round(max_return, 2),  # ì†Œìˆ˜ì  2ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
                'max_loss': round(max_loss, 2),  # ì†Œìˆ˜ì  2ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
                'estimated_profit_rate': round(estimated_profit_rate, 2),  # ì†Œìˆ˜ì  2ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
                'risk_adjusted_return': round(risk_adjusted_return, 2), # risk_adjusted_return ê°’ ì¶”ê°€
                'confidence': round(confidence, 4),   # confidence ê°’ ì €ì¥
            })
        
        # ì§„í–‰ ìƒí™© ì¶œë ¥
        if (index + 1) % 10 == 0 or (index + 1) == len(validation_results):
            print(f"Evaluated performance for {index + 1}/{len(validation_results)} patterns")
    
    performance_df = pd.DataFrame(performance_results)
    return performance_df

def send_validation_summary(validation_results, performance_df, settings):

    print("\n=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===")
    
    # ê²€ì¦ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    total_predictions = len(validation_results)
    total_performance = len(performance_df)
    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {total_predictions}")
    print(f"ì„±ê³¼ í‰ê°€ ìˆ˜: {total_performance}")
    
    if not performance_df.empty:

        avg_return = performance_df['estimated_profit_rate'].mean()
        avg_risk_adjusted_return = performance_df['risk_adjusted_return'].mean()
        max_return = performance_df['max_return'].max()
        max_loss = performance_df['max_loss'].min()

        print(f"í‰ê·  ìµœëŒ€ ìˆ˜ìµë¥ : {avg_return:.2f}%")
        print(f"ìµœê³  ìˆ˜ìµë¥ : {max_return:.2f}%")
        print(f"ìµœê³  ì†ì‹¤ë¥ : {max_loss:.2f}%")
        
        # ë‚ ì§œë³„ ìƒìœ„ ì¢…ëª© ë¶„ì„
        try:
            results, summaries = analyze_top_performers_by_date(performance_df, top_n=3)
            
            # ì—¬ëŸ¬ ë‚ ì§œë¥¼ ëª¨ì•„ì„œ ë³´ë‚´ê¸° ìœ„í•œ ë³€ìˆ˜ë“¤
            batch_size = 8  # í•œ ë²ˆì— ë³´ë‚¼ ë‚ ì§œ ìˆ˜ (5 ë˜ëŠ” 7ë¡œ ì„¤ì •)
            messages_batch = []
            batch_counter = 0
            
            for i, result in enumerate(results):
                date = result['date']
                top_stocks = result['top_stocks']
                
                # í˜„ì¬ ë‚ ì§œ ì •ë³´ ë©”ì‹œì§€ ìƒì„±
                current_message = f"\nğŸ“…ë‚ ì§œ: {date}\n"
                current_message += "ì¢…ëª©ëª… | Confidence | ìµœëŒ€ ìˆ˜ìµë¥  | ìµœëŒ€ ì†ì‹¤ | ì˜ˆìƒ ìˆ˜ìµë¥  | ìœ„í—˜ ì¡°ì • ìˆ˜ìµë¥ \n"
                for _, row in top_stocks.iterrows():
                    current_message += (
                        f"{row['stock_name']} | {row['confidence']:.4f} | "
                        f"{row['max_return']:.2f}% | {row['max_loss']:.2f}% | "
                        f"{row['estimated_profit_rate']:.2f}% | {row['risk_adjusted_return']:.2f}%\n"
                    )
                
                # ë°°ì¹˜ì— í˜„ì¬ ë©”ì‹œì§€ ì¶”ê°€
                messages_batch.append(current_message)
                batch_counter += 1
                
                # ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ê±°ë‚˜ ë§ˆì§€ë§‰ ê²°ê³¼ì¸ ê²½ìš° ë©”ì‹œì§€ ì „ì†¡
                if batch_counter >= batch_size or i == len(results) - 1:
                    # ë°°ì¹˜ ë©”ì‹œì§€ ìƒì„± ë° ì „ì†¡
                    batch_message = "=== ë‚ ì§œë³„ ìƒìœ„ 3ê°œ ì¢…ëª© ===\n" + "\n".join(messages_batch)
                    send_telegram_message(settings['telegram_token'], settings['telegram_chat_id'], batch_message)
                    
                    # ë°°ì¹˜ ì´ˆê¸°í™”
                    messages_batch = []
                    batch_counter = 0
            
            # ê²€ì¦ ê²°ê³¼ ìš”ì•½ ë©”ì‹œì§€ ë³„ë„ë¡œ ì „ì†¡
            summary_message = ("\n=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===\n"
                f"ëª¨ë¸ : {settings['model_name']}\n"
                f"ì´ ì˜ˆì¸¡ ìˆ˜: {total_predictions}\n"
                f"ì„±ê³¼ í‰ê°€ ìˆ˜: {total_performance}\n"
                f"í‰ê·  ìµœëŒ€ ìˆ˜ìµë¥ : {avg_return:.2f}%\n"
                f"í‰ê·  risk adjusted return: {avg_risk_adjusted_return:.2f}%\n"
                f"ìµœê³  ìˆ˜ìµë¥ : {max_return:.2f}%\n"
                f"ìµœì € ì†ì‹¤ë¥ : {max_loss:.2f}%\n"
            )
            send_telegram_message(settings['telegram_token'], settings['telegram_chat_id'], summary_message)
            
        except Exception as e:
            print(f"Error analyzing top performers: {e}")
            import traceback
            traceback.print_exc()
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ ìš”ì•½ ë©”ì‹œì§€ë§Œ ì „ì†¡
            summary_message = ("\n=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===\n"
                f"ëª¨ë¸ : {settings['model_name']}\n"
                f"ì´ ì˜ˆì¸¡ ìˆ˜: {total_predictions}\n"
                f"ì„±ê³¼ í‰ê°€ ìˆ˜: {total_performance}\n"
                f"í‰ê·  ìµœëŒ€ ìˆ˜ìµë¥ : {avg_return:.2f}%\n"
                f"í‰ê·  risk adjusted return: {avg_risk_adjusted_return:.2f}%\n"
                f"ìµœê³  ìˆ˜ìµë¥ : {max_return:.2f}%\n"
                f"ìµœì € ì†ì‹¤ë¥ : {max_loss:.2f}%\n"
            )
            send_telegram_message(settings['telegram_token'], settings['telegram_chat_id'], summary_message)

    else:
        print("ì„±ê³¼ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        message = (
            "=== ê²€ì¦ ê²°ê³¼ ìš”ì•½ ===\n"
            f"ì´ ì˜ˆì¸¡ ìˆ˜: {total_predictions}\n"
            f"ì„±ê³¼ í‰ê°€ ìˆ˜: {total_performance}\n"
            "ì„±ê³¼ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.\n"
        )
        send_telegram_message(settings['telegram_token'], settings['telegram_chat_id'], message)



def analyze_top_performers_by_date(performance_df, top_n=3):
    """ë‚ ì§œë³„ë¡œ ìƒìœ„ ì„±ê³¼ë¥¼ ë³´ì¸ ì¢…ëª©ì„ ë¶„ì„"""
    try:
        # 'date' ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ í™•ì¸
        if 'date' not in performance_df.columns:
            print("Error: 'date' column is missing in performance_df.")
            return [], pd.DataFrame()
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•˜ê¸° ì „ì— stock_nameê³¼ date ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
        performance_df = performance_df.drop_duplicates(subset=['stock_name', 'date'])
        
        # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        performance_df['date'] = pd.to_datetime(performance_df['date'])
        date_grouped = performance_df.groupby(performance_df['date'].dt.date)
        
        results = []
        date_summaries = []
        
        # ê° ë‚ ì§œë³„ë¡œ ì²˜ë¦¬
        for date, group in date_grouped:
            print(f"\në‚ ì§œ: {date} - Prediction ê¸°ì¤€ ìƒìœ„ {top_n}ê°œ ì¢…ëª©")
            # prediction ê¸°ì¤€ ìƒìœ„ ì¢…ëª© ì„ íƒ
            top_stocks = group.nlargest(top_n, 'confidence')
            print(f"ë‚ ì§œ: {date} - ìƒìœ„ {top_n}ê°œ ì¢…ëª©:\n{top_stocks}")  # ì¶”ê°€ëœ ë¡œê·¸ ë©”ì‹œì§€
            # ë‚ ì§œë³„ ìš”ì•½ í†µê³„
            date_summary = {
                'date': date,
                'total_patterns': len(group),
                'avg_risk_adjusted_return': group['risk_adjusted_return'].mean(),
                'avg_max_return': group['estimated_profit_rate'].mean(),
                'top_performer': top_stocks.iloc[0]['stock_name'] if len(top_stocks) > 0 else None,
                'top_return': top_stocks.iloc[0]['risk_adjusted_return'] if len(top_stocks) > 0 else None
            }
            
            date_summaries.append(date_summary)
            results.append({'date': date, 'top_stocks': top_stocks})
        
        return results, pd.DataFrame(date_summaries)
    except Exception as e:
        print(f"Error analyzing top performers: {e}")
        import traceback
        traceback.print_exc()
        return [], pd.DataFrame()

def save_performance_to_deeplearning(predictions_df, settings):
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ deep_learning í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        # Get db_manager and model_name from settings
        db_manager = settings['buy_list_db']
        model_name = settings.get('model_name', 'xgboost')
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ìƒíƒœ í™•ì¸
        if not db_manager.engine:
            print("Database connection is not available.")
            return False

        # í•„ìš”í•œ ì»¬ëŸ¼ ì¶”ì¶œ ë° ì´ë¦„ ë³€ê²½
        dl_data = predictions_df.copy()
        
        # ëª¨ë¸ ì´ë¦„ ì„¤ì •
        method_name = model_name
        dl_data['method'] = method_name
        
        # í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        keep_columns = ['date', 'method', 'stock_name', 'confidence', 'estimated_profit_rate', 'risk_adjusted_return']
        all_columns = list(dl_data.columns)
        
        # ìœ ì§€í•  ì»¬ëŸ¼ë§Œ ì„ íƒ (ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ)
        columns_to_keep = [col for col in keep_columns if col in all_columns]
        dl_data = dl_data[columns_to_keep]
        
        # notes ì»¬ëŸ¼ ì¶”ê°€
        dl_data['notes'] = f"Generated by {method_name} on {pd.Timestamp.now().strftime('%Y-%m-%d')}"
        
        # ì¤‘ìš”: NaN, ë¬´í•œê°’(inf) ì²˜ë¦¬ - MySQLì€ inf/nan ê°’ì„ ì €ì¥í•  ìˆ˜ ì—†ìŒ
        for column in dl_data.select_dtypes(include=['float', 'float64']).columns:
            dl_data[column] = dl_data[column].replace([np.nan, float('inf'), float('-inf')], None)
        
        # ë””ë²„ê·¸ ì •ë³´ ì¶œë ¥
        print("ì €ì¥ ì „ ë°ì´í„° ìƒ˜í”Œ:")
        print(dl_data.head().to_dict('records'))
        
        # ë°ì´í„° ì €ì¥
        result = db_manager.to_sql_replace(dl_data, 'deep_learning')
        if result:
            print(f"âœ… {len(dl_data)}ê°œì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ deep_learning í…Œì´ë¸”ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return result
    except Exception as e:
        print(f"âŒ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False


